{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä An√°lise de Pr√©-processamento de Dados\n",
    "\n",
    "Este notebook analisa um dataset e determina automaticamente se voc√™ deve usar:\n",
    "- ‚úÖ Apenas escalonamento\n",
    "- ‚úÖ Apenas transforma√ß√£o\n",
    "- ‚úÖ Transforma√ß√£o + escalonamento\n",
    "- ‚úÖ Nenhum dos dois\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Importa√ß√£o de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, normaltest, skew, kurtosis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Carregamento dos Dados\n",
    "\n",
    "**Instru√ß√µes:** Altere o caminho do arquivo para o seu dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregue seu dataset aqui\n",
    "df = pd.read_csv('/mnt/user-data/uploads/1761482687687_pasted-content-1761482687686.txt')\n",
    "\n",
    "print(f\"‚úì Dataset carregado: {df.shape[0]} linhas, {df.shape[1]} colunas\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Classe Analisadora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalisadorPreProcessamento:\n",
    "    \"\"\"Classe para analisar necessidade de pr√©-processamento\"\"\"\n",
    "    \n",
    "    def __init__(self, df, target_col='target'):\n",
    "        \"\"\"\n",
    "        Inicializa o analisador\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pd.DataFrame\n",
    "            Dataset a ser analisado\n",
    "        target_col : str\n",
    "            Nome da coluna target (ser√° exclu√≠da da an√°lise)\n",
    "        \"\"\"\n",
    "        self.df = df.copy()\n",
    "        self.target_col = target_col\n",
    "        \n",
    "        # Separar features num√©ricas (excluindo target e colunas n√£o num√©ricas)\n",
    "        self.features = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if target_col in self.features:\n",
    "            self.features.remove(target_col)\n",
    "        \n",
    "        # Remover colunas com todos valores iguais ou NaN\n",
    "        self.features = [col for col in self.features \n",
    "                        if self.df[col].nunique() > 1 and self.df[col].notna().sum() > 0]\n",
    "        \n",
    "        self.resultados = {}\n",
    "        \n",
    "    def calcular_estatisticas(self):\n",
    "        \"\"\"Calcula estat√≠sticas descritivas de cada feature\"\"\"\n",
    "        print(\"=\" * 80)\n",
    "        print(\"üìä ESTAT√çSTICAS DESCRITIVAS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        estatisticas = []\n",
    "        \n",
    "        for col in self.features:\n",
    "            dados = self.df[col].dropna()\n",
    "            \n",
    "            if len(dados) == 0:\n",
    "                continue\n",
    "                \n",
    "            stats_dict = {\n",
    "                'Feature': col,\n",
    "                'Min': dados.min(),\n",
    "                'Max': dados.max(),\n",
    "                'Mean': dados.mean(),\n",
    "                'Median': dados.median(),\n",
    "                'Std': dados.std(),\n",
    "                'Range': dados.max() - dados.min(),\n",
    "                'Zeros_%': (dados == 0).sum() / len(dados) * 100,\n",
    "                'Skewness': skew(dados),\n",
    "                'Kurtosis': kurtosis(dados)\n",
    "            }\n",
    "            estatisticas.append(stats_dict)\n",
    "        \n",
    "        self.stats_df = pd.DataFrame(estatisticas)\n",
    "        print(f\"\\n‚úì Analisadas {len(self.features)} features num√©ricas\\n\")\n",
    "        \n",
    "        return self.stats_df\n",
    "    \n",
    "    def analisar_escala(self):\n",
    "        \"\"\"Analisa a necessidade de escalonamento\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üìè AN√ÅLISE DE ESCALA\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Calcular ranges e magnitudes\n",
    "        ranges = self.stats_df['Range'].values\n",
    "        max_range = ranges.max()\n",
    "        min_range = ranges[ranges > 0].min() if any(ranges > 0) else 0\n",
    "        \n",
    "        # Verificar disparidade de escalas\n",
    "        if min_range > 0:\n",
    "            ratio_escala = max_range / min_range\n",
    "        else:\n",
    "            ratio_escala = np.inf\n",
    "        \n",
    "        print(f\"\\nüìä Estat√≠sticas de Escala:\")\n",
    "        print(f\"   ‚Ä¢ Range m√≠nimo: {min_range:.2e}\")\n",
    "        print(f\"   ‚Ä¢ Range m√°ximo: {max_range:.2e}\")\n",
    "        print(f\"   ‚Ä¢ Raz√£o max/min: {ratio_escala:.2e}\")\n",
    "        \n",
    "        # Crit√©rios para recomendar escalonamento\n",
    "        precisa_escalonamento = False\n",
    "        razoes = []\n",
    "        \n",
    "        if ratio_escala > 100:\n",
    "            precisa_escalonamento = True\n",
    "            razoes.append(f\"Grande disparidade de escalas (raz√£o = {ratio_escala:.0f}x)\")\n",
    "        \n",
    "        # Verificar features com diferentes ordens de magnitude\n",
    "        magnitudes = self.stats_df['Max'].apply(lambda x: np.floor(np.log10(abs(x) + 1)))\n",
    "        diff_magnitudes = magnitudes.max() - magnitudes.min()\n",
    "        \n",
    "        if diff_magnitudes > 3:\n",
    "            precisa_escalonamento = True\n",
    "            razoes.append(f\"Features com diferentes ordens de magnitude (diferen√ßa: {diff_magnitudes:.0f})\")\n",
    "        \n",
    "        self.resultados['escalonamento'] = {\n",
    "            'necessario': precisa_escalonamento,\n",
    "            'razoes': razoes,\n",
    "            'ratio_escala': ratio_escala,\n",
    "            'diff_magnitudes': diff_magnitudes\n",
    "        }\n",
    "        \n",
    "        if precisa_escalonamento:\n",
    "            print(f\"\\n‚úÖ ESCALONAMENTO RECOMENDADO\")\n",
    "            print(f\"\\nMotivos:\")\n",
    "            for r in razoes:\n",
    "                print(f\"   ‚Ä¢ {r}\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå ESCALONAMENTO N√ÉO NECESS√ÅRIO\")\n",
    "            print(f\"   ‚Ä¢ Escalas relativamente uniformes\")\n",
    "        \n",
    "        return precisa_escalonamento\n",
    "    \n",
    "    def analisar_normalidade(self):\n",
    "        \"\"\"Analisa a normalidade e necessidade de transforma√ß√£o\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üìà AN√ÅLISE DE NORMALIDADE E ASSIMETRIA\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        features_problematicas = []\n",
    "        \n",
    "        for col in self.features[:20]:  # An√°lise detalhada das primeiras 20\n",
    "            dados = self.df[col].dropna()\n",
    "            \n",
    "            if len(dados) < 3:\n",
    "                continue\n",
    "            \n",
    "            # Calcular m√©tricas\n",
    "            sk = skew(dados)\n",
    "            kt = kurtosis(dados)\n",
    "            \n",
    "            # Teste de normalidade\n",
    "            if len(dados) >= 8:\n",
    "                try:\n",
    "                    _, p_shapiro = shapiro(dados[:5000])  # Limitar para performance\n",
    "                except:\n",
    "                    p_shapiro = 1.0\n",
    "            else:\n",
    "                p_shapiro = 1.0\n",
    "            \n",
    "            # Identificar problemas\n",
    "            problemas = []\n",
    "            if abs(sk) > 1:\n",
    "                problemas.append(f\"Alta assimetria ({sk:.2f})\")\n",
    "            if abs(kt) > 3:\n",
    "                problemas.append(f\"Curtose anormal ({kt:.2f})\")\n",
    "            if p_shapiro < 0.05:\n",
    "                problemas.append(\"N√£o-normal (p<0.05)\")\n",
    "            \n",
    "            if problemas:\n",
    "                features_problematicas.append({\n",
    "                    'feature': col,\n",
    "                    'skewness': sk,\n",
    "                    'kurtosis': kt,\n",
    "                    'p_value': p_shapiro,\n",
    "                    'problemas': problemas\n",
    "                })\n",
    "        \n",
    "        print(f\"\\nüìä Resumo da An√°lise:\")\n",
    "        print(f\"   ‚Ä¢ Features analisadas: {min(20, len(self.features))}\")\n",
    "        print(f\"   ‚Ä¢ Features com problemas: {len(features_problematicas)}\")\n",
    "        \n",
    "        if features_problematicas:\n",
    "            print(f\"\\n‚ö†Ô∏è  Features mais problem√°ticas (top 10):\")\n",
    "            sorted_features = sorted(features_problematicas, \n",
    "                                   key=lambda x: abs(x['skewness']), \n",
    "                                   reverse=True)[:10]\n",
    "            \n",
    "            for i, feat in enumerate(sorted_features, 1):\n",
    "                print(f\"\\n   {i}. {feat['feature']}\")\n",
    "                print(f\"      Skewness: {feat['skewness']:.3f}\")\n",
    "                print(f\"      Kurtosis: {feat['kurtosis']:.3f}\")\n",
    "                print(f\"      p-value: {feat['p_value']:.4f}\")\n",
    "        \n",
    "        # An√°lise de assimetria geral\n",
    "        skewness_values = self.stats_df['Skewness'].abs()\n",
    "        \n",
    "        pct_alta_assimetria = (skewness_values > 1).sum() / len(skewness_values) * 100\n",
    "        pct_moderada_assimetria = ((skewness_values > 0.5) & (skewness_values <= 1)).sum() / len(skewness_values) * 100\n",
    "        \n",
    "        print(f\"\\nüìà Distribui√ß√£o de Assimetria:\")\n",
    "        print(f\"   ‚Ä¢ Alta assimetria (|skew| > 1): {pct_alta_assimetria:.1f}%\")\n",
    "        print(f\"   ‚Ä¢ Moderada (0.5 < |skew| ‚â§ 1): {pct_moderada_assimetria:.1f}%\")\n",
    "        print(f\"   ‚Ä¢ Baixa (|skew| ‚â§ 0.5): {100 - pct_alta_assimetria - pct_moderada_assimetria:.1f}%\")\n",
    "        \n",
    "        # Decis√£o sobre transforma√ß√£o\n",
    "        precisa_transformacao = pct_alta_assimetria > 30 or len(features_problematicas) > len(self.features) * 0.3\n",
    "        \n",
    "        self.resultados['transformacao'] = {\n",
    "            'necessario': precisa_transformacao,\n",
    "            'pct_alta_assimetria': pct_alta_assimetria,\n",
    "            'features_problematicas': len(features_problematicas),\n",
    "            'total_features': len(self.features)\n",
    "        }\n",
    "        \n",
    "        if precisa_transformacao:\n",
    "            print(f\"\\n‚úÖ TRANSFORMA√á√ÉO RECOMENDADA\")\n",
    "            print(f\"\\nMotivos:\")\n",
    "            print(f\"   ‚Ä¢ {pct_alta_assimetria:.1f}% das features t√™m alta assimetria\")\n",
    "            print(f\"   ‚Ä¢ {len(features_problematicas)} features com distribui√ß√£o problem√°tica\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå TRANSFORMA√á√ÉO N√ÉO NECESS√ÅRIA\")\n",
    "            print(f\"   ‚Ä¢ Maioria das features tem distribui√ß√£o aceit√°vel\")\n",
    "        \n",
    "        return precisa_transformacao\n",
    "    \n",
    "    def analisar_outliers(self):\n",
    "        \"\"\"Analisa a presen√ßa de outliers\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üéØ AN√ÅLISE DE OUTLIERS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        outliers_info = []\n",
    "        \n",
    "        for col in self.features:\n",
    "            dados = self.df[col].dropna()\n",
    "            \n",
    "            if len(dados) < 4:\n",
    "                continue\n",
    "            \n",
    "            Q1 = dados.quantile(0.25)\n",
    "            Q3 = dados.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            lower_bound = Q1 - 3 * IQR\n",
    "            upper_bound = Q3 + 3 * IQR\n",
    "            \n",
    "            outliers = ((dados < lower_bound) | (dados > upper_bound)).sum()\n",
    "            pct_outliers = outliers / len(dados) * 100\n",
    "            \n",
    "            if pct_outliers > 0:\n",
    "                outliers_info.append({\n",
    "                    'feature': col,\n",
    "                    'n_outliers': outliers,\n",
    "                    'pct_outliers': pct_outliers\n",
    "                })\n",
    "        \n",
    "        # Ordenar por percentual\n",
    "        outliers_info.sort(key=lambda x: x['pct_outliers'], reverse=True)\n",
    "        \n",
    "        print(f\"\\nüìä Resumo:\")\n",
    "        print(f\"   ‚Ä¢ Features com outliers: {len(outliers_info)}/{len(self.features)}\")\n",
    "        \n",
    "        if outliers_info:\n",
    "            print(f\"\\n‚ö†Ô∏è  Top 10 features com mais outliers:\")\n",
    "            for i, info in enumerate(outliers_info[:10], 1):\n",
    "                print(f\"   {i}. {info['feature']}: {info['n_outliers']} outliers ({info['pct_outliers']:.2f}%)\")\n",
    "        \n",
    "        # Calcular m√©dia de outliers\n",
    "        if outliers_info:\n",
    "            media_pct_outliers = np.mean([x['pct_outliers'] for x in outliers_info])\n",
    "            print(f\"\\n   M√©dia de outliers: {media_pct_outliers:.2f}%\")\n",
    "            \n",
    "            if media_pct_outliers > 5:\n",
    "                print(f\"\\nüí° DICA: Transforma√ß√µes como Yeo-Johnson podem ajudar a reduzir o impacto dos outliers\")\n",
    "        \n",
    "        self.resultados['outliers'] = outliers_info\n",
    "        \n",
    "        return outliers_info\n",
    "    \n",
    "    def gerar_visualizacoes(self, n_features=6):\n",
    "        \"\"\"Gera visualiza√ß√µes das features mais problem√°ticas\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üìä GERANDO VISUALIZA√á√ïES\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Selecionar features com maior assimetria\n",
    "        features_sorted = self.stats_df.nlargest(n_features, 'Skewness')['Feature'].tolist()\n",
    "        \n",
    "        fig, axes = plt.subplots(n_features, 2, figsize=(15, 4*n_features))\n",
    "        \n",
    "        for i, col in enumerate(features_sorted):\n",
    "            dados = self.df[col].dropna()\n",
    "            \n",
    "            # Histograma\n",
    "            axes[i, 0].hist(dados, bins=50, edgecolor='black', alpha=0.7)\n",
    "            axes[i, 0].set_title(f'{col}\\nHistograma', fontweight='bold')\n",
    "            axes[i, 0].set_xlabel('Valor')\n",
    "            axes[i, 0].set_ylabel('Frequ√™ncia')\n",
    "            \n",
    "            # Adicionar estat√≠sticas\n",
    "            sk = skew(dados)\n",
    "            kt = kurtosis(dados)\n",
    "            axes[i, 0].text(0.02, 0.98, f'Skew: {sk:.2f}\\nKurt: {kt:.2f}',\n",
    "                          transform=axes[i, 0].transAxes,\n",
    "                          verticalalignment='top',\n",
    "                          bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "            \n",
    "            # Boxplot\n",
    "            axes[i, 1].boxplot(dados, vert=False)\n",
    "            axes[i, 1].set_title(f'{col}\\nBoxplot', fontweight='bold')\n",
    "            axes[i, 1].set_xlabel('Valor')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"‚úì Visualiza√ß√µes de distribui√ß√µes geradas\")\n",
    "        \n",
    "        # Gr√°fico de resumo de assimetria\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        # Selecionar top 20 features por assimetria\n",
    "        top_skewed = self.stats_df.nlargest(20, 'Skewness', keep='all')\n",
    "        \n",
    "        colors = ['red' if abs(x) > 1 else 'orange' if abs(x) > 0.5 else 'green' \n",
    "                 for x in top_skewed['Skewness']]\n",
    "        \n",
    "        ax.barh(range(len(top_skewed)), top_skewed['Skewness'], color=colors, alpha=0.7)\n",
    "        ax.set_yticks(range(len(top_skewed)))\n",
    "        ax.set_yticklabels(top_skewed['Feature'], fontsize=8)\n",
    "        ax.set_xlabel('Skewness', fontweight='bold')\n",
    "        ax.set_title('Top 20 Features por Assimetria', fontsize=14, fontweight='bold')\n",
    "        ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "        ax.axvline(x=-1, color='red', linestyle=':', alpha=0.5, label='|skew| = 1')\n",
    "        ax.axvline(x=1, color='red', linestyle=':', alpha=0.5)\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"‚úì Gr√°fico de assimetria gerado\")\n",
    "    \n",
    "    def gerar_recomendacao_final(self):\n",
    "        \"\"\"Gera recomenda√ß√£o final com base em todas as an√°lises\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üéØ RECOMENDA√á√ÉO FINAL\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        precisa_escalonamento = self.resultados['escalonamento']['necessario']\n",
    "        precisa_transformacao = self.resultados['transformacao']['necessario']\n",
    "        \n",
    "        print(f\"\\nüìã An√°lise Completa:\")\n",
    "        print(f\"   ‚Ä¢ Escalonamento necess√°rio: {'SIM ‚úÖ' if precisa_escalonamento else 'N√ÉO ‚ùå'}\")\n",
    "        print(f\"   ‚Ä¢ Transforma√ß√£o necess√°ria: {'SIM ‚úÖ' if precisa_transformacao else 'N√ÉO ‚ùå'}\")\n",
    "        \n",
    "        print(f\"\\n\" + \"‚îÄ\" * 80)\n",
    "        \n",
    "        if precisa_transformacao and precisa_escalonamento:\n",
    "            print(f\"\\nüîß RECOMENDA√á√ÉO: TRANSFORMA√á√ÉO + ESCALONAMENTO\")\n",
    "            print(f\"\\nüìù Pipeline Recomendado:\")\n",
    "            print(f\"   1Ô∏è‚É£  Yeo-Johnson ou Box-Cox (transforma√ß√£o)\")\n",
    "            print(f\"   2Ô∏è‚É£  Sele√ß√£o de Features\")\n",
    "            print(f\"   3Ô∏è‚É£  StandardScaler ou RobustScaler (escalonamento)\")\n",
    "            print(f\"   4Ô∏è‚É£  Modelo\")\n",
    "            \n",
    "            print(f\"\\nüí° Justificativa:\")\n",
    "            print(f\"   ‚Ä¢ Dados apresentam alta assimetria ({self.resultados['transformacao']['pct_alta_assimetria']:.1f}% features)\")\n",
    "            print(f\"   ‚Ä¢ Escalas muito diferentes entre features (raz√£o: {self.resultados['escalonamento']['ratio_escala']:.0f}x)\")\n",
    "            print(f\"   ‚Ä¢ Transforma√ß√£o corrige distribui√ß√µes antes da sele√ß√£o de features\")\n",
    "            print(f\"   ‚Ä¢ Escalonamento garante magnitude compar√°vel para o modelo\")\n",
    "            \n",
    "        elif precisa_transformacao:\n",
    "            print(f\"\\nüîß RECOMENDA√á√ÉO: APENAS TRANSFORMA√á√ÉO\")\n",
    "            print(f\"\\nüìù Pipeline Recomendado:\")\n",
    "            print(f\"   1Ô∏è‚É£  Yeo-Johnson ou Box-Cox (transforma√ß√£o)\")\n",
    "            print(f\"   2Ô∏è‚É£  Sele√ß√£o de Features\")\n",
    "            print(f\"   3Ô∏è‚É£  Modelo\")\n",
    "            \n",
    "            print(f\"\\nüí° Justificativa:\")\n",
    "            print(f\"   ‚Ä¢ Dados apresentam alta assimetria ({self.resultados['transformacao']['pct_alta_assimetria']:.1f}% features)\")\n",
    "            print(f\"   ‚Ä¢ Escalas relativamente uniformes\")\n",
    "            print(f\"   ‚Ä¢ Transforma√ß√£o melhorar√° a normalidade para modelos que assumem isso\")\n",
    "            \n",
    "        elif precisa_escalonamento:\n",
    "            print(f\"\\nüîß RECOMENDA√á√ÉO: APENAS ESCALONAMENTO\")\n",
    "            print(f\"\\nüìù Pipeline Recomendado:\")\n",
    "            print(f\"   1Ô∏è‚É£  Sele√ß√£o de Features (se usar m√©todos sens√≠veis √† escala)\")\n",
    "            print(f\"   2Ô∏è‚É£  StandardScaler ou MinMaxScaler\")\n",
    "            print(f\"   3Ô∏è‚É£  Modelo\")\n",
    "            \n",
    "            print(f\"\\nüí° Justificativa:\")\n",
    "            print(f\"   ‚Ä¢ Grande disparidade de escalas (raz√£o: {self.resultados['escalonamento']['ratio_escala']:.0f}x)\")\n",
    "            print(f\"   ‚Ä¢ Distribui√ß√µes relativamente normais\")\n",
    "            print(f\"   ‚Ä¢ Escalonamento evitar√° domin√¢ncia de features com valores grandes\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\nüîß RECOMENDA√á√ÉO: NENHUM PR√â-PROCESSAMENTO OBRIGAT√ìRIO\")\n",
    "            print(f\"\\nüìù Pipeline Recomendado:\")\n",
    "            print(f\"   1Ô∏è‚É£  Sele√ß√£o de Features (m√©todos baseados em √°rvores funcionam bem)\")\n",
    "            print(f\"   2Ô∏è‚É£  Modelo\")\n",
    "            \n",
    "            print(f\"\\nüí° Justificativa:\")\n",
    "            print(f\"   ‚Ä¢ Escalas relativamente uniformes\")\n",
    "            print(f\"   ‚Ä¢ Distribui√ß√µes aceit√°veis\")\n",
    "            print(f\"   ‚Ä¢ Considere usar modelos baseados em √°rvores (Random Forest, XGBoost)\")\n",
    "        \n",
    "        print(f\"\\n\" + \"‚îÄ\" * 80)\n",
    "        \n",
    "        return precisa_transformacao, precisa_escalonamento\n",
    "\n",
    "print(\"‚úÖ Classe AnalisadorPreProcessamento criada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Execu√ß√£o da An√°lise\n",
    "\n",
    "### Configura√ß√£o\n",
    "\n",
    "**Importante:** Altere o nome da coluna target se necess√°rio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar inst√¢ncia do analisador\n",
    "analisador = AnalisadorPreProcessamento(df, target_col='target')\n",
    "\n",
    "print(f\"‚úì Analisador criado com sucesso!\")\n",
    "print(f\"‚úì Features num√©ricas identificadas: {len(analisador.features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Estat√≠sticas Descritivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = analisador.calcular_estatisticas()\n",
    "\n",
    "# Visualizar as 10 primeiras features\n",
    "stats_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ An√°lise de Escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisa_escalonamento = analisador.analisar_escala()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ An√°lise de Normalidade e Assimetria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisa_transformacao = analisador.analisar_normalidade()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ An√°lise de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_info = analisador.analisar_outliers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5Ô∏è‚É£ Visualiza√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar visualiza√ß√µes das 6 features mais assim√©tricas\n",
    "analisador.gerar_visualizacoes(n_features=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6Ô∏è‚É£ Recomenda√ß√£o Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisa_transformacao, precisa_escalonamento = analisador.gerar_recomendacao_final()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª Exemplo de Pipeline\n",
    "\n",
    "Com base na an√°lise acima, aqui est√° um exemplo de c√≥digo para implementar o pipeline recomendado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Separar features e target\n",
    "X = df.drop(columns=['target', 'os_timestamp', 'node_name'], errors='ignore')\n",
    "y = df['target']\n",
    "\n",
    "# Manter apenas features num√©ricas\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"‚úì Dados preparados:\")\n",
    "print(f\"   ‚Ä¢ X_train: {X_train.shape}\")\n",
    "print(f\"   ‚Ä¢ X_test: {X_test.shape}\")\n",
    "print(f\"   ‚Ä¢ Features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline baseado na recomenda√ß√£o\n",
    "if precisa_transformacao and precisa_escalonamento:\n",
    "    print(\"üìù Criando pipeline com: Transforma√ß√£o + Sele√ß√£o + Escalonamento + Modelo\")\n",
    "    pipeline = Pipeline([\n",
    "        ('transformer', PowerTransformer(method='yeo-johnson')),\n",
    "        ('selector', SelectKBest(f_classif, k=20)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "elif precisa_transformacao:\n",
    "    print(\"üìù Criando pipeline com: Transforma√ß√£o + Sele√ß√£o + Modelo\")\n",
    "    pipeline = Pipeline([\n",
    "        ('transformer', PowerTransformer(method='yeo-johnson')),\n",
    "        ('selector', SelectKBest(f_classif, k=20)),\n",
    "        ('model', LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "elif precisa_escalonamento:\n",
    "    print(\"üìù Criando pipeline com: Sele√ß√£o + Escalonamento + Modelo\")\n",
    "    pipeline = Pipeline([\n",
    "        ('selector', SelectKBest(f_classif, k=20)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "else:\n",
    "    print(\"üìù Criando pipeline com: Sele√ß√£o + Modelo (√°rvores)\")\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    pipeline = Pipeline([\n",
    "        ('selector', SelectKBest(f_classif, k=20)),\n",
    "        ('model', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "\n",
    "print(\"‚úÖ Pipeline criado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar e avaliar\n",
    "print(\"üöÄ Treinando o modelo...\\n\")\n",
    "\n",
    "# Cross-validation\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"üìä Resultados da Valida√ß√£o Cruzada (5-fold):\")\n",
    "print(f\"   ‚Ä¢ Acur√°cias: {scores}\")\n",
    "print(f\"   ‚Ä¢ M√©dia: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "\n",
    "# Treinar no conjunto completo de treino\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Avaliar no teste\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "print(f\"\\n‚úì Acur√°cia no conjunto de teste: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Exportar Estat√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar estat√≠sticas em CSV\n",
    "stats_df.to_csv('estatisticas_features.csv', index=False)\n",
    "print(\"‚úÖ Estat√≠sticas salvas em: estatisticas_features.csv\")\n",
    "\n",
    "# Visualizar resumo\n",
    "print(\"\\nüìã Resumo das Estat√≠sticas:\")\n",
    "print(f\"   ‚Ä¢ Total de features analisadas: {len(stats_df)}\")\n",
    "print(f\"   ‚Ä¢ Features com alta assimetria (|skew|>1): {(stats_df['Skewness'].abs() > 1).sum()}\")\n",
    "print(f\"   ‚Ä¢ Range m√©dio: {stats_df['Range'].mean():.2e}\")\n",
    "print(f\"   ‚Ä¢ Desvio padr√£o m√©dio: {stats_df['Std'].mean():.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Conclus√µes\n",
    "\n",
    "### Resumo da An√°lise:\n",
    "\n",
    "Execute todas as c√©lulas acima para ver:\n",
    "- ‚úÖ Se seu dataset precisa de **transforma√ß√£o** (Yeo-Johnson/Box-Cox)\n",
    "- ‚úÖ Se seu dataset precisa de **escalonamento** (StandardScaler/MinMaxScaler)\n",
    "- ‚úÖ A **ordem correta** do pipeline de pr√©-processamento\n",
    "- ‚úÖ Visualiza√ß√µes das distribui√ß√µes mais problem√°ticas\n",
    "- ‚úÖ C√≥digo pronto para implementa√ß√£o\n",
    "\n",
    "### üí° Dicas Finais:\n",
    "\n",
    "1. **Sempre use Pipelines** do scikit-learn para evitar data leakage\n",
    "2. **Transforma√ß√£o vem antes** da sele√ß√£o de features\n",
    "3. **Escalonamento vem depois** da sele√ß√£o de features\n",
    "4. Para **modelos baseados em √°rvores**, transforma√ß√£o e escalonamento geralmente n√£o s√£o necess√°rios\n",
    "5. Use **PowerTransformer** com `method='yeo-johnson'` pois aceita valores negativos\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Notebook criado com sucesso!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
